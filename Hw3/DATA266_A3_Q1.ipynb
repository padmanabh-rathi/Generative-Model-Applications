{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Q1. Try out different prompt engineering techniques such as Zero-Shot, Few-Shot, Chain-of-Thought, Zero-Shot CoT, Meta-Prompting, and Tree of Thoughts. For with your own examples in (like math, logic, or text tasks). Compare how the outputs differ and document findings."
      ],
      "metadata": {
        "id": "Dzw_gNHfqxVG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WF8yVn-jopqU",
        "outputId": "950b27fd-2a41-4a14-9c00-b7f457065273"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (1.107.0)\n",
            "Collecting openai\n",
            "  Downloading openai-1.108.1-py3-none-any.whl.metadata (29 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.11.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
            "Downloading openai-1.108.1-py3-none-any.whl (948 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m948.4/948.4 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.107.0\n",
            "    Uninstalling openai-1.107.0:\n",
            "      Successfully uninstalled openai-1.107.0\n",
            "Successfully installed openai-1.108.1\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.75)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.11)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.4.27)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.11.7)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.0.43)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.32.4)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (4.15.0)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.24.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2025.8.3)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.10.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (1.1.1)\n"
          ]
        }
      ],
      "source": [
        "# update or install the necessary libraries\n",
        "!pip install --upgrade openai\n",
        "!pip install --upgrade langchain\n",
        "!pip install --upgrade python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41Y9UQZsqw7o",
        "outputId": "82da08ee-0a6e-452e-ca63-45a56e03bedb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.29-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=0.3.75 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.3.75)\n",
            "Requirement already satisfied: langchain<2.0.0,>=0.3.27 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.3.27)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.43)\n",
            "Collecting requests<3,>=2.32.5 (from langchain-community)\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.12.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (8.5.0)\n",
            "Collecting dataclasses-json<0.7,>=0.6.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.10.1)\n",
            "Requirement already satisfied: langsmith>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.27)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.6.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.6.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain<2.0.0,>=0.3.27->langchain-community) (0.3.11)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain<2.0.0,>=0.3.27->langchain-community) (2.11.7)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=0.3.75->langchain-community) (1.33)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=0.3.75->langchain-community) (4.15.0)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=0.3.75->langchain-community) (25.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.125->langchain-community) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.125->langchain-community) (0.24.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.1.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.32.5->langchain-community) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.32.5->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.32.5->langchain-community) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.32.5->langchain-community) (2025.8.3)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.2.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (4.10.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<2.0.0,>=0.3.75->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.27->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.27->langchain-community) (2.33.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.6.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.3.1)\n",
            "Downloading langchain_community-0.3.29-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: requests, mypy-extensions, marshmallow, typing-inspect, dataclasses-json, langchain-community\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.4\n",
            "    Uninstalling requests-2.32.4:\n",
            "      Successfully uninstalled requests-2.32.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dataclasses-json-0.6.7 langchain-community-0.3.29 marshmallow-3.26.1 mypy-extensions-1.1.0 requests-2.32.5 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import os\n",
        "import IPython\n",
        "from langchain.llms import OpenAI\n",
        "from dotenv import load_dotenv"
      ],
      "metadata": {
        "id": "SpnjI7OVrPLs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Directly set the API key\n",
        "api_key = \"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\"\n",
        "openai.api_key = api_key\n",
        "os.environ[\"OPENAI_API_KEY\"] = api_key  # For LangChain compatibility\n"
      ],
      "metadata": {
        "id": "mPhWhHPYrQ8q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def set_open_params(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    temperature=0.7,\n",
        "    max_tokens=256,\n",
        "    top_p=1,\n",
        "    frequency_penalty=0,\n",
        "    presence_penalty=0,\n",
        "):\n",
        "    \"\"\" set openai parameters\"\"\"\n",
        "\n",
        "    openai_params = {}\n",
        "\n",
        "    openai_params['model'] = model\n",
        "    openai_params['temperature'] = temperature\n",
        "    openai_params['max_tokens'] = max_tokens\n",
        "    openai_params['top_p'] = top_p\n",
        "    openai_params['frequency_penalty'] = frequency_penalty\n",
        "    openai_params['presence_penalty'] = presence_penalty\n",
        "    return openai_params\n",
        "\n",
        "def get_completion(params, messages):\n",
        "    \"\"\" GET completion from openai api\"\"\"\n",
        "\n",
        "    response = openai.chat.completions.create(\n",
        "        model = params['model'],\n",
        "        messages = messages,\n",
        "        temperature = params['temperature'],\n",
        "        max_tokens = params['max_tokens'],\n",
        "        top_p = params['top_p'],\n",
        "        frequency_penalty = params['frequency_penalty'],\n",
        "        presence_penalty = params['presence_penalty'],\n",
        "    )\n",
        "    return response"
      ],
      "metadata": {
        "id": "dF9kQdO7reat"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# basic example\n",
        "params = set_open_params()\n",
        "\n",
        "prompt = \"The sky is\"\n",
        "\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": prompt\n",
        "    }\n",
        "]\n",
        "\n",
        "response = get_completion(params, messages)"
      ],
      "metadata": {
        "id": "ZVs7DUMXri9t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response.choices[0].message.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "I_y5eFMyryEh",
        "outputId": "770b07c4-0f86-4c73-e5b5-173e3e4efa29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"The sky is a vast expanse above us, often perceived as a canvas that changes with the time of day and weather. During the day, it's typically a vibrant blue due to the scattering of sunlight, while at sunrise and sunset, it can display stunning hues of orange, pink, and purple. At night, the sky transforms into a dark backdrop sprinkled with stars, planets, and sometimes the glow of the moon. It plays a crucial role in our climate, weather patterns, and even in cultural symbolism across different societies. What specific aspect of the sky are you interested in?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Zero-Shot**"
      ],
      "metadata": {
        "id": "9uZc7UhOtOCd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Zero-Shot Example\n",
        "\n",
        "# set parameters\n",
        "params = set_open_params()\n",
        "\n",
        "# we are choosing a logical task\n",
        "prompt = \"If Alice is taller than Bob and Bob is taller than Charlie, who is tallest?\"\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": prompt}\n",
        "]\n",
        "\n",
        "# get response\n",
        "response = get_completion(params, messages)\n",
        "\n",
        "# print output\n",
        "print(\"Zero-Shot Prompt:\", prompt)\n",
        "print(\"Model Output:\", response.choices[0].message.content.strip())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVvrGH_DtDQr",
        "outputId": "76d25e80-2c2e-447c-ba6e-44f6da61d6fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Zero-Shot Prompt: If Alice is taller than Bob and Bob is taller than Charlie, who is tallest?\n",
            "Model Output: If Alice is taller than Bob and Bob is taller than Charlie, then Alice is the tallest.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Few-Shot**"
      ],
      "metadata": {
        "id": "MjsWfoaztu5g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Few-Shot Example\n",
        "\n",
        "# set parameters\n",
        "params = set_open_params()\n",
        "\n",
        "# few-shot prompt with examples , for this technique we are again taking logical question\n",
        "prompt = \"\"\"Answer the following questions about who is tallest:\n",
        "\n",
        "Example 1:\n",
        "If John is taller than Mike and Mike is taller than Sarah, who is tallest?\n",
        "Answer: John\n",
        "\n",
        "Example 2:\n",
        "If Emma is taller than Noah and Noah is taller than Olivia, who is tallest?\n",
        "Answer: Emma\n",
        "\n",
        "Now try to answer this one:\n",
        "If Alice is taller than Bob and Bob is taller than Charlie, who is tallest?\n",
        "Answer:\"\"\"\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": prompt}\n",
        "]\n",
        "\n",
        "# get response\n",
        "response = get_completion(params, messages)\n",
        "\n",
        "# print output\n",
        "print(\"Few-Shot Prompt:\\n\", prompt)\n",
        "print(\"Model Output:\", response.choices[0].message.content.strip())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbJl6tlgtV2t",
        "outputId": "82aec27f-2b5b-40d8-f6b8-d929ecfc0cc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Few-Shot Prompt:\n",
            " Answer the following questions about who is tallest:\n",
            "\n",
            "Example 1:\n",
            "If John is taller than Mike and Mike is taller than Sarah, who is tallest?\n",
            "Answer: John\n",
            "\n",
            "Example 2:\n",
            "If Emma is taller than Noah and Noah is taller than Olivia, who is tallest?\n",
            "Answer: Emma\n",
            "\n",
            "Now try to answer this one:\n",
            "If Alice is taller than Bob and Bob is taller than Charlie, who is tallest?\n",
            "Answer:\n",
            "Model Output: Alice\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Chain-of-Thought**"
      ],
      "metadata": {
        "id": "zNmxP0-5v1Fb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chain-of-Thought (CoT) Example\n",
        "\n",
        "# set parameters\n",
        "params = set_open_params()\n",
        "\n",
        "# In CoT, we explicitly ask the model to \"think step by step\"\n",
        "# This forces the model to show its reasoning process before giving the final answer\n",
        "prompt = \"\"\"If Alice is taller than Bob and Bob is taller than Charlie,\n",
        "who is tallest? Think step by step and then give the final answer.\"\"\"\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": prompt}\n",
        "]\n",
        "\n",
        "# get response from the model\n",
        "response = get_completion(params, messages)\n",
        "\n",
        "# print both the prompt and model output\n",
        "print(\"Chain-of-Thought Prompt:\\n\", prompt)\n",
        "print(\"Model Output (with reasoning):\", response.choices[0].message.content.strip())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RaKKlb8Jv0vl",
        "outputId": "19a8b593-c1e1-4fc3-f94b-0bb2efd1ee05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chain-of-Thought Prompt:\n",
            " If Alice is taller than Bob and Bob is taller than Charlie,\n",
            "who is tallest? Think step by step and then give the final answer.\n",
            "Model Output (with reasoning): Let's break down the information given step by step:\n",
            "\n",
            "1. We know that Alice is taller than Bob. This can be represented as:\n",
            "   - Alice > Bob\n",
            "\n",
            "2. We also know that Bob is taller than Charlie. This can be represented as:\n",
            "   - Bob > Charlie\n",
            "\n",
            "Now, we can combine these two pieces of information to determine the relative heights of Alice, Bob, and Charlie:\n",
            "\n",
            "- Since Alice is taller than Bob (Alice > Bob) and Bob is taller than Charlie (Bob > Charlie), we can conclude that:\n",
            "  - Alice is also taller than Charlie.\n",
            "\n",
            "This gives us the hierarchy of heights:\n",
            "- Alice > Bob > Charlie\n",
            "\n",
            "From this hierarchy, we can see that Alice is the tallest among the three individuals.\n",
            "\n",
            "Final answer: Alice is the tallest.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Zero-Shot CoT**"
      ],
      "metadata": {
        "id": "hy4-zqsYwj0x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Zero-Shot Chain-of-Thought (Zero-Shot CoT) Example\n",
        "\n",
        "# set parameters\n",
        "params = set_open_params()\n",
        "\n",
        "# Zero-Shot CoT means no examples are provided (zero-shot) but we add a \"reasoning like word\" like \"Let's think step by step\" to push the model towards reasoning\n",
        "prompt = \"\"\"If Alice is taller than Bob and Bob is taller than Charlie,\n",
        "who is tallest? Let's think step by step.\"\"\"\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": prompt}\n",
        "]\n",
        "\n",
        "# get response from the model\n",
        "response = get_completion(params, messages)\n",
        "\n",
        "# print both the prompt and model output\n",
        "print(\"Zero-Shot CoT Prompt:\\n\", prompt)\n",
        "print(\"Model Output (with reasoning):\", response.choices[0].message.content.strip())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0JROf5UgwjZS",
        "outputId": "3b5afe1d-aeec-4078-cb1c-d248622e3f64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Zero-Shot CoT Prompt:\n",
            " If Alice is taller than Bob and Bob is taller than Charlie,\n",
            "who is tallest? Let's think step by step.\n",
            "Model Output (with reasoning): Let's break it down step by step:\n",
            "\n",
            "1. We know that Alice is taller than Bob. This means:\n",
            "   - Alice > Bob\n",
            "\n",
            "2. We also know that Bob is taller than Charlie. This means:\n",
            "   - Bob > Charlie\n",
            "\n",
            "3. Combining these two pieces of information, we can infer the following relationships:\n",
            "   - Since Alice is taller than Bob (Alice > Bob) and Bob is taller than Charlie (Bob > Charlie), we can conclude that Alice is also taller than Charlie.\n",
            "   - Therefore, we have: Alice > Bob > Charlie.\n",
            "\n",
            "From this, we can determine that the tallest person among Alice, Bob, and Charlie is Alice.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Meta-Prompting**"
      ],
      "metadata": {
        "id": "RY8QCx4kxb1g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Meta-Prompting Example\n",
        "\n",
        "# set parameters\n",
        "params = set_open_params()\n",
        "\n",
        "# In case of Meta-Prompting we give the model instructions on HOW to behave or solve the problem (e.g., act like a teacher).\n",
        "prompt = \"\"\"You are a logic teacher.\n",
        "Explain your reasoning clearly, step by step, and then provide the final answer.\n",
        "Question: If Alice is taller than Bob and Bob is taller than Charlie, who is tallest?\n",
        "\"\"\"\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": prompt}\n",
        "]\n",
        "\n",
        "# get response from the model\n",
        "response = get_completion(params, messages)\n",
        "\n",
        "# print both the prompt and model output\n",
        "print(\"Meta-Prompting Prompt:\\n\", prompt)\n",
        "print(\"Model Output (teacher-style reasoning):\", response.choices[0].message.content.strip())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h2b4zRqzxPEX",
        "outputId": "89c0a5f3-b69f-45e1-9660-c40fc23f4ff7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Meta-Prompting Prompt:\n",
            " You are a logic teacher. \n",
            "Explain your reasoning clearly, step by step, and then provide the final answer.\n",
            "Question: If Alice is taller than Bob and Bob is taller than Charlie, who is tallest?\n",
            "\n",
            "Model Output (teacher-style reasoning): To determine who is the tallest among Alice, Bob, and Charlie, we can analyze the information given step by step.\n",
            "\n",
            "1. **Information Given**:\n",
            "   - Alice is taller than Bob.\n",
            "   - Bob is taller than Charlie.\n",
            "\n",
            "2. **Translating the Information into Relationships**:\n",
            "   - From the first statement, we can express the relationship as:\n",
            "     - \\( A > B \\) (Alice is taller than Bob)\n",
            "   - From the second statement, we can express the relationship as:\n",
            "     - \\( B > C \\) (Bob is taller than Charlie)\n",
            "\n",
            "3. **Combining the Relationships**:\n",
            "   - Since we know that \\( A > B \\) and \\( B > C \\), we can infer that:\n",
            "     - If \\( A > B \\) and \\( B > C \\), then it follows that \\( A > C \\) (Alice is also taller than Charlie).\n",
            "\n",
            "4. **Conclusion**:\n",
            "   - We have established the following order of height:\n",
            "     - Alice > Bob > Charlie\n",
            "   - Therefore, Alice is the tallest of the three.\n",
            "\n",
            "Thus, the final answer is: **Alice is the tallest.**\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tree of Thoughts**"
      ],
      "metadata": {
        "id": "uJaq6waLyHNn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tree of Thoughts (ToT) Example\n",
        "\n",
        "# set parameters\n",
        "params = set_open_params()\n",
        "\n",
        "# Tree of Thoughts explores multiple possible reasoning paths (\"thoughts\") then evaluates and selects the best answer in the below example we explicitly ask the model to consider different reasoning paths\n",
        "prompt = \"\"\"Solve the following step by step using multiple possible reasoning paths.\n",
        "Explore at least two reasoning options before deciding on the best one.\n",
        "Question: If Alice is taller than Bob and Bob is taller than Charlie, who is tallest?\n",
        "\"\"\"\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": prompt}\n",
        "]\n",
        "\n",
        "# get response from the model\n",
        "response = get_completion(params, messages)\n",
        "\n",
        "# print both the prompt and model output\n",
        "print(\"Tree of Thoughts Prompt:\\n\", prompt)\n",
        "print(\"Model Output (multiple reasoning paths):\", response.choices[0].message.content.strip())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EyujEDvhyAQP",
        "outputId": "37b562be-f805-45a7-f5c4-7e6eef103095"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tree of Thoughts Prompt:\n",
            " Solve the following step by step using multiple possible reasoning paths.\n",
            "Explore at least two reasoning options before deciding on the best one. \n",
            "Question: If Alice is taller than Bob and Bob is taller than Charlie, who is tallest?\n",
            "\n",
            "Model Output (multiple reasoning paths): To solve the problem, we need to analyze the relationships between the heights of Alice, Bob, and Charlie based on the information provided. We can approach it in two different ways to ensure we reach the correct conclusion.\n",
            "\n",
            "### Reasoning Path 1: Direct Comparison\n",
            "1. **Identify the Relationships**:\n",
            "   - We know that Alice is taller than Bob (A > B).\n",
            "   - We also know that Bob is taller than Charlie (B > C).\n",
            "\n",
            "2. **Transitive Property**:\n",
            "   - Since A > B and B > C, by the transitive property of inequality, we can deduce that A > C.\n",
            "   - This means Alice is taller than Charlie.\n",
            "\n",
            "3. **Final Comparison**:\n",
            "   - Now we have:\n",
            "     - A > B (Alice is taller than Bob)\n",
            "     - A > C (Alice is taller than Charlie)\n",
            "     - B > C (Bob is taller than Charlie)\n",
            "   - Therefore, since Alice is taller than both Bob and Charlie, **Alice is the tallest**.\n",
            "\n",
            "### Reasoning Path 2: Visual Representation\n",
            "1. **Create a Height Order**:\n",
            "   - We can represent the heights in a visual manner:\n",
            "     - Alice (A) > Bob (B) > Charlie (C)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below are my findings :\n",
        "\n",
        "- With Zero-Shot, the model gave the correct answer directly without any explanation. In Few-Shot, the model also answered correctly, but this time it relied on the pattern from the earlier examples provided in the prompt. Both produced the right answer, but Few-Shot showed the benefit of giving prior context.\n",
        "\n",
        "- The Chain-of-Thought version expanded the reasoning in detail. It broke the problem into smaller steps, showed the relationships (Alice > Bob, Bob > Charlie), and then combined them before reaching the conclusion. Zero-Shot CoT did almost the same thing, but with slightly less structured explanation, since it was only triggered by “let’s think step by step.”\n",
        "\n",
        "- In Meta-Prompting, the output followed the role instruction closely. The model explained the reasoning as if teaching, with a structured, teacher-like explanation and even used mathematical notation to represent the comparisons.\n",
        "\n",
        "- Finally, Tree of Thoughts produced multiple reasoning paths. It first solved the problem using direct comparison and then validated it again with a visual representation. This approach was more elaborate compared to the others because it explored alternatives before deciding.\n",
        "\n",
        "- Overall, while all methods led to the same final answer (“Alice is the tallest”), the style and depth of reasoning differed."
      ],
      "metadata": {
        "id": "taN_mzSE0lu9"
      }
    }
  ]
}